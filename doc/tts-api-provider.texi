\input texinfo   @c -*-texinfo-*-
@c %**start of header
@setfilename tts-api-provider.info
@settitle TTS API Provider
@finalout
@c @setchapternewpage odd
@c %**end of header

@copying
Copyright @copyright{} 2006, 2007 Brailcom, o.p.s.
All rights reserved.

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.2 or
any later version published by the Free Software Foundation; with no
Invariant Sections, with no Front-Cover Texts and no Back-Cover Texts.
A copy of the license is included in the section entitled ``GNU Free
Documentation License.''
@end quotation

A copy of the license is included in the section entitled ``GNU
General Public License''
@end copying

@c @set version 2006-03-09

@c Directory, keywords
@dircategory Sound
@dircategory Development
@dircategory Accessibility

@direntry
* TTS API Provider: (tts-api).    TTS API Provider
@end direntry

@c Title page for printed version
@titlepage
@title TTS API Provider 

@author Hynek Hanke, Brailcom <@email{hanke@@brailcom.org}>
@author Jan Buchal, Brailcom <@email{buchal@@brailcom.org}>
@author Gary Cramblitt, KDE <@email{garycramblitt@@comcast.net}> 

@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage
@contents

@c Title page for INFO
@ifnottex
@node Top, Introduction, (dir), (dir)
@top TTS API Provider
@insertcopying
@end ifnottex

@menu
* Introduction::                
* Design::                      
* Server Implementation::       
* Device Driver Implementation::  
* TTS API Implementations::     
@end menu

@node Introduction, Design, Top, Top
@chapter Introduction

TTS API Provider is a system service providing applications with
low-level access to various synthesizers via TTS API (See TTS API
specification, @uref{http://www.freebsoft.org/tts-api}). It manages
the synthesizers available on the system and provides a unified
interface to them.

This API was developed in cooperation between the biggest Free
Software accessibility projects at that time (Gnome Accessibility
Project, KDE Accessibility, Free-b-Soft and others). It is made
available publicly and separately in the hope to unify our efforts,
revise the speech output architecture and put it on solid, well
designed, well documented and de-facto standardized grounds. Its
target is on accessibility, however we believe it is powerful enough
to be useful in other areas too where speech synthesis is useful.

Our publishing of the API and making it available on the system for
easy use should however not be seen as an encouragement for developers
to use this low-level API directly! Most applications, especially
accessibility applications, should never contact this low-level API
directly. They should use a high-level API such as one of the Speech
Dispatchers APIs, Gnome Speech API or KTTS API doing the necessary
coordination of messages from various applications. To put it simple,
one should only use TTS API Provider directly and fully if he is sure
he is authorized to take complete control over all speech synthesis
audio output on the system. As mentioned, this is mostly never the
case of ordinary applications. In the audio world, the issue could be
compared to applications taking control over the /dev/dsp device
(under OSS) or intentionally bypassing the mixer (under ALSA) and thus
blocking others. @footnote{While sound output for various concurrent
speech streams is not a problem any longer, if it is done without any
attempt at coordination and control, the result will likely be that
the user can't understand any of the streams.}  An exception to this
rule are applications on embedded systems, highly specialized
applications like telephony servers, speech synthesis research and
development applications and applications who only retrieve the
synthesized audio samples but do not play them on the sound card
(e.g. a text2wav converter).  If in doubt, please contact us.

@node Design, Server Implementation, Introduction, Top
@chapter Design

TTS API Provider is composed of four independent parts.  The
@emph{provider itself}, running on the system and interfacing
applications with speech synthesizers and doing the necessary
emulations, the various @emph{drivers} that translate the APIs of the
synthesizers into TTS API, @emph{driver template library} to help with
developement of drivers and @emph{convenience libraries} which provide
easy access to TTS API from various languages.

@menu
* General Design::              
* TTS API Provider (core)::     
* Drivers::                     
* Driver Template Library::     
* Convenience Libraries for Applications::  
@end menu

@node General Design, TTS API Provider (core), Design, Design
@section General Design

The intended middle-term design, as also described in other sections
in this chapter, is demonstrated on the following picture. Please keep
in mind the picture was not meant to be exhaustive and only contains
the main ideas and some examples.

@image{figures/architecture,155mm,,TTS API Provider architecture}

Such an architecture is not ideal, however. The optimal future design
is demonstrated on the picture bellow. Most important, TTS API
Provider should not have to take care of directly handling audio
devices and doing its own audio output. This is a task unrelated to
the Text-to-Speech process, necessary for many other applications
outside the domain of speech synthesis and accessibility, and as such
would best be left to an independent component. Only because currently
we do not know of any general Free Software audio component that could
handle our needs, we will temporarily continue to provide our own
basic audio output.

@image{figures/architecture-future,155mm,,TTS API Provider architecture in the future}

Also, ideally, audio should not be transported through the engine
driver, but could be directed from the synthesizer itself directly to
the destination, lowering the latency and transport overhead, as
is illustrated on the picture in case of Festival.

@node TTS API Provider (core), Drivers, General Design, Design
@section TTS API Provider (core)

@heading Functionality

@itemize
    @item manage all drivers
    @item emulate necessary functionality not supported by the drivers
    @item provide interface to applications
@end itemize

@heading Implementation

@itemize
@item License: GNU GPL
@item Language: Python
@item Dependencies: Python
@end itemize

TTS API Provider will be a separate process for the following
reasons:

@itemize
@item
There will be only one instance of it running on the system at a given
time, which simplifies things like rereading configuration after
configuration change, maintaining context on simple non-context
synthesizers (!), solving of conflicts in access to hardware
synthesizers. It will make it possible not to lunch unnecessarily many
drivers for one synthesizer (!).

@item
Applications won't have compile dependency on TTS API Provider.

@item
Applications won't be affected by TTS API Provider stability.

@item
The language of implementation of TTS API Provider is not important
for the applications.

@item
Problems with TTS API Provider will be easier to diagnose for the user
and its debugging will be easier for the developers.

@item
Communication can be led over network.
@end itemize

TTS API Provider communication layer will provide a TCP version of TTS
API. This TCP inter-process communication will be wrapped in
convenience libraries (4) for easy use in the application. Care will
be taken to avoid dependency on this particular communication method
so that in the future, other IPC methods like Corba or DBUS can be
added if necessary.

TTS API Provider will automatically launch available engine
drivers. In order to achieve context independency of clients, to allow
more clients to perform synthesis at once and to keep the synthesizer
drivers simple (not require them to explicitly handle various
clients), it might sometimes be necessary to have several instances of
a driver running to serve the various clients.

TTS API Provider will temporarily handle audio output if
necessary. Audio output code should not be a part of TTS API Provider,
but currently no audio output framework is available on the Free
Software platform which would fit our needs. The audio handling part
is to be removed as soon as such a framework is available.

TTS API Provider will emulate the necessary functionality that is
reported by the synthesizer drivers through TTS API as
non-available. The most important examples are: SSML to plain-text
conversion, context switching and breaking of long text into smaller
chunks.

TTS API Provider will provide the defer() and say_deferred() mechanism
for all synthesizers (maintaining the necessary heap of messages for
synthesizers who do not support it). This will significantly release
implementation burden on the applications.

@node Drivers, Driver Template Library, TTS API Provider (core), Design
@section Drivers

@heading Functionality

@itemize
@item initialization of and communication with synthesizers
@item conversion between TTS API and synthesizer API
@item only emulate functionality where necessary
for conversion between TTS API and synthesizer API
@end itemize

@heading Implementation

@itemize @w{}
@item @emph{License}: various
@item @emph{Language}: various, most often C
@item @emph{Dependencies}: various, driver template library
@end itemize

Drivers will be separate processes as is completely necessary
for legal reasons and for the reasons of stability.

Drivers can be built using the driver template library (3),
although this is not necessary.

Drivers will communicate in the same TCP version of TTS API through
pipes, reading from their standard input and writing to their standard
output.

@node Driver Template Library, Convenience Libraries for Applications, Drivers, Design
@section Driver Template Library

@heading Functionality:
@itemize
@item take care of IPC communication (TTS API + audio socket)
@item provide the necessary infrastructure (threads etc.)
so that the driver author can only implement the necessary TTS
API functions
@item provide tools to make conversion between TTS API and the various
synthesizer APIs easier
@end itemize

@heading Implementation
@itemize @w{}
@item @emph{License}: GNU LGPL
@item @emph{Language}: Python, C
@item @emph{Dependencies}: python, glibc
@end itemize

@node Convenience Libraries for Applications,  , Driver Template Library, Design
@section Convenience Libraries for Applications

@heading Functionality

@itemize
@item expose a simple library version of TTS API and take
care of	IPC communication
@end itemize

@heading Implementation

@itemize @w{}
@item @emph{License}: GNU LGPL
@item @emph{Language}: C, Python
@item @emph{Dependencies}: libc, Python
@end itemize

@node Server Implementation, Device Driver Implementation, Design, Top
@chapter Server Implementation

This chapter roughly describes the implementation of TTS API provider,
including the related subsystems (driver templates, audio subsystem
etc.). This chapter should rather be seen more as an introduction
guide for new developers than an exhaustive technical code
documentation.  Please note that this description is not necessarily
up to date. Ultimate documentation for the implementation are the
abundant comments in the source code itself.

@menu
* TTS API Provider Core (implementation)::  
* Audio Subsystem (implementation)::  
@end menu

@node TTS API Provider Core (implementation), Audio Subsystem (implementation), Server Implementation, Server Implementation
@section TTS API Provider core (implementation)

TTS API Provider is a thread-based server. Handling of each client is
done in a separate thread which in turn operates a separate set of
output drivers. This is highly convenient as by a design decision,
there are made no assumptions on interaction between the various
clients.  In other words, the design must allow for multiple clients
handling their synthesis requests and speaking at the same time. This
allows higher level layers using TTS API to do a very sophisticated
message coordination including serialized AND concurent speech, 3D
aural speech from multiple sources etc.

The main server with its daemon functionality (pidfile, signals,
terminal detaching, global state of the server and global audio events
receiver) is implemented in the source file @file{src/server.py}. The
server is currently based on TCP communication and TCP communication
should remain a part of the functionality. However, it is by no means
restricted to TCP communication. @file{src/server.py} can be extended
to include also other means of communication (DBUS, etc.) without
loosing the Provider functionality provided by the underlaying
modules. For such reason, care is taken to distinguish between the
different modes of communication in paramters passed forward even
though currently text-based TCP (or pipes) is the only option.

@heading Connection handling

When a new connection is obtained, a new thread is created running the
@code{serve_client} function found in the same source
file. @code{serve_client} starts a new @code{provider.Provider}
object. The global logging, configuration, audio (subsystem) are
passed to the Provider object on initialization.

A second object of the family @code{ttsapi.server.} is then created to
handle the connection. It is given the new @code{provider.Provider}
object as its parameter. Its method @code{connection.process_input()}
is then being called in a loop. This connection object will process
the input from the communication channel and call the appropriate
communication-mechanism independent method of the object
@code{Provider}. @code{provider.Provider} is then responsible for
providing the TTS API functionality, emulations and communication with
the device drivers. It roughly implements the Python version of TTS API.

@heading Audio Event Delivery Thread

One thread is launched by the TTS API Provider right on its start.  It
is the Audio Event Delivery Thread running as function
@code{audio_event_delivery} implemented in @file{src/server.py}.
This thread listens for all audio events delivered to TTS API Provider
from the audio subsystem and dispatches them to the various
@code{provider.Provider} objects associated with the appropriate
connection to which this audio event belongs.

Please note that it is important not to slide into the temptation of
delivering audio events from the audio subsystem to the provider
objects directly as it is a design decision to eventually split the
audio subsystem and TTS API provider into different servers. (The
idea is to use some global Free Software audio subsystem when one
appears that fulfills the Accessibility Audio Framework Requirements
and drop our own codebase). Once such a transition is achieved, events
will necessarily be delivered into the server as a whole, not directly
to the @code{provider.Provider} instances, so it will only be
necessary to modify the @code{audio_event_delivery} method if this
strict separation is maintained.

For more information about the audio subsystem, please see @xref{Audio
Subsystem (implementation)}.

@heading Provider Object

The @code{Provider} object is implemented in the file
@file{src/provider.py} and implements the core functionality of TTS API
Provider in a client-server communication method independent way. On
initialization, it starts its own set of device driver
processes. Communication with the device drivers is currently led in
the text-based pipe version of TTS API, the same code in
@file{src/ttsapi/server.py} is used as for communication between
clients and provider. Please refer to TTS API definition document,
@xref{Python TTS API}, and the source code itself for description of
the available methods and their function.

With regards to @code{emulation} of missing capabilities in the
drivers: Ideally, all emulation should be done in the provider object
by cooperation with its subsystems whenever the driver reports that a
capability is not available. Generally useful emulations like
character caching, defer, text-substitution (punctuation, capital
letters) and index marking emulation etc. should not be done in the
drivers as this unnecessarily blows their codebase, reduces
readability and necessarily leads to duplication of code. Emulations
that do not emulate TTS API @code{MUST HAVE} functionality must be
configurable.

The provider object recognizes three audio output methods:
@itemize
@item retrieval -- audio data will be retrieved to client application
@item playback -- the synthesizer will play the audio data on speakers
@item emulated_playback -- audio data will be passed to the TTS API Provider
audio subsystem for playback
@end itemize

Methods @code{retrieval} and @code{emulated_playback} are only
available if the device can return the synthesized data to the caller.
For simple hardware synthesizers, only method playback is available.
However, when both playback and retrieval are available by the device
itself and the client requests playback, Provider will use
'emulated_playback' so that we have full control over the playback
and we do not have to deal with the (usually numerous) bugs in
synthesizers implementation of audio output (device blocking etc.)
according to the TTS API Provider design decisions.

If method @code{emulated_playback} is being used, the @code{say_}
functions need to notify the audio subsystem about the new message
identification and tell it to expect new audio data in its audio data bin.
Also request for playback must be sent whenever necessary. Please see the
method @code{provider._prepare_for_message} in @file{src/provider.py}.

@node Audio Subsystem (implementation),  , TTS API Provider Core (implementation), Server Implementation
@section Audio Subsystem (implementation)


@node Device Driver Implementation, TTS API Implementations, Server Implementation, Top
@chapter Device Driver Implementation

Device drivers are implemented as separate processes that are being
launched by the TTS API Provider Core. All communication between the
core and the drivers happens through the text protocol TTS API via pipes
(stdin, stdout and stderr of the said process). As such, drivers can be
implemented in any programming language as long as they conform to the
prescribed interface. 

We provide libraries for Python and C which make implementation of the
device drivers quite simple by handling the questions of communication,
logging and internal structure (such as threading) automatically. Their
use is recommended for ease and consistency, programmers are however
free to implement their device drivers in a different way or in
a different programming language.

@menu
* Driver Interface::            
* Drivers in Python::           
* Drivers in C::                
@end menu

@node Driver Interface, Drivers in Python, Device Driver Implementation, Device Driver Implementation
@section Driver Interface

The drivers communicate using the standard TTS API implemented as a text
protocol, with a few exceptions listed bellow. Input/output happens on
standard input and standard output of the device driver process. All
logging messages should be written in the selected level of verbosity
to the standard error output.

Differencies from the standard TTS API:
@itemize 
@item INIT
The very first command sent to the driver process must be the
@code{INIT} command. On receiving this command, the device driver should
initialize itself (connect to the synthesizer, test if the connection is
working etc.) and report success or error together with a reason for the
error in a human readable form.

If the driver reports an error during initialization, the provider
core is responsible for sending the QUIT command subsequently and
thus terminating the driver process.

It is an error to call any other TTS API command before @code{INIT} or
to call @code{INIT} more than once.

Example with successful initialization:
@example
INIT
200 OK INITIALIZED SUCCESFULLY
@end example

Example with error during initialization:
@example
INIT
304-"Festival driver not loaded, server not running."
304 DRIVER NOT LOADED
QUIT
@end example

@item LIST DRIVERS
This command provides only one entry in its reply which is corresponding
to the name and version of the synthesizer handled by this driver.

@item SET DRIVER
This command is not used. Attempts to call it should result in an
@code{INVALID COMMAND} error reply.

@item HELP
This command is not used by the Provider. If is up to the driver
author whether he implements it.

@end itemize

@node Drivers in Python, Drivers in C, Driver Interface, Device Driver Implementation
@section Drivers in Python

A convenience library and a prepared skelton for developing Python
device drivers can be found in
@file{tts-api-provider/src/provider/driver.py}. This file is basically a
full implementation of a driver that does nothing :)

@menu
* Driver Design (Python)::      
* Driver skeleton (Python)::    
* Core (Python)::               
* Controller (Python)::         
* RetrievalSocket (Python)::    
* Other tools::                 
@end menu

@node Driver Design (Python), Driver skeleton (Python), Drivers in Python, Drivers in Python
@subsection Driver Design (Python)

There are two possible ways how to create a device driver:

@itemize
@item Bottom-up: By overriding some methods of the provided classes that should
contain code specific for your drivers while using the provided
skeleton.
@item Top-Down: By creating your own skeleton of the driver process while
using some of the provided classes for some of the tasks that
you need to accomplish.
@end itemize

Unless your driver is very specific, we recommend using the bottom-up
approach, which should be considerably easier to implement.

@node Driver skeleton (Python), Core (Python), Driver Design (Python), Drivers in Python
@subsection Driver skeleton (Python)

To use the provided driver skeleton, create a new script which calls the
method @code{driver.main_loop(DriverCore, DriverController)} where
@code{DriverCore} and @code{DriverController} are instances of classes
defining the driver functionality. Normally they are derived from the
base classes @code{driver.Core} and @code{driver.Controller} and
reimplement only those methods specific to the driver in question. For
that reason, if you consider writing a device driver in Python, you are
very much encouraged to study the contents of
@file{src/provider/driver.py} carefully.

Basically, @code{DriverCore} is the main ,,provider'' object which
implements all the TTS API functionality methods, like
@code{Core.set_rate}, @code{Core.say_text} or @code{Core.say_key}. Some
of the methods like @code{Core.say_text}, @code{Core.say_key} or
@code{Core.cancel} are by default pre-programmed so that they accept the
request only, pass it for processing to the appropriate
@code{DriverController} method which runs in a separate thread, and
return. While the @code{DriverCore} methods must be non-blocking
(i.e. @code{SAY TEXT} must return immediatelly as per definition of TTS
API), there is no such restriction on the @code{DriverController}
methods, which are launched in a separate thread, and can run during the
whole time of the synthesis and/or audio playback of the requested
message.

It is enough for a programmer to override the
@code{driver.Core.say_text()} method if he doesn't need the asynchronous
functionality of the @code{driver.Controller} object. If the synthesizer
is blocking however, the driver programmer can make advantage of the
provided mechanism by overriding the @code{driver.Controller.say_text()}
method instead without having to create his own threads and locks for
that purpose.

@node Core (Python), Controller (Python), Driver skeleton (Python), Drivers in Python
@subsection Core (Python)

The @code{Core} object provides the main functionality of the driver.
It implements all driver TTS API methods. Every method has a set of
parameters and a return value as defined in TTS API and documented in
@file{src/provider/driver.py}. If not overriden, most of these methods
raise the @code{ttsapi.error.ErrorNotSupportedByDriver} exception.

@enumerate
@item 
It is not necessary to implement all the methods, the driver author must
however allways make sure that the state of implementation of the
@code{DriverCore} methods is consistent with the capabilities list
returned by the @code{DriverCore.capabilities()} method.

Notes:
@item
It is necessary to run @code{super(Core, self).init()} and
@code{super(Core, self).quit()} at the end of your own code if you
override the @code{Core.init} or @code{Core.quit} methods so that the
@code{DriverController} thread is handled correctly.
@end enumerate

Please see inline documentation in @file{src/provider/driver.py} for
more information about the class and its methods and
@file{src/provider/festival.py} for an example.


@node Controller (Python), RetrievalSocket (Python), Core (Python), Drivers in Python
@subsection Controller (Python)

The controller object contains the following TTS API methods:

@itemize
@item say_text
@item say_key
@item say_char
@item say_icon
@item cancel
@item defer
@item discard
@end itemize

Instead of overriding these methods in @code{DriverCore}, they can be
overriden in the @code{DriverController} object. The methods in this
later object are called one after each other in a lateral thread.  The
execution mechanism is implemented in the @code{run} method which we
recommend to study as well.

The parameters and return values of the @code{DriverController} TTS API
methods are exactly the same as those for the @code{DriverCore} methods.

Please note that if you redefine the primary @code{DriverCore} method,
e.g. @code{say_text}, without calling the @code{super} method of the
parent, the appropriate @code{DriverController} method will never get
called. It is thus allways only reasonable to redefine one of those
two methods.

Example: A very common case will be the @code{say_text} method
implemented in the @code{DriverController} object while the
@code{cancel} method is implemented in the @code{DriverCore} object.
This way, the @code{say_text} method can be blocking (in the lateral
thread) during the whole time of synthesis playback, while the
@code{cancel} method in the @code{DriverCore} object in the main thread
can still be called to stop the 'blocking' synthesis code.

Please see inline documentation in @file{src/provider/driver.py} for
more information about the class and its methods and
@file{src/provider/festival.py} for an example.

@node RetrievalSocket (Python), Other tools, Controller (Python), Drivers in Python
@subsection RetrievalSocket (Python)

The @code{RetrievalSocket} class allows the module to open an audio
retrieval socket connection (as defined by TTS API) to the given host
and port and send blocks of audio data via the @code{send_data_block}
method.

Drivers that support the 'retrieval' method of audio output but the
underlaying synthesizer doesn't support it, must retrieve the data
from the synthesizer via the offered mechanism and send them to their
desired destination via the TTS API retrieval socket. Creating an
object of the @code{RetrievalSocket} class is the prefered way
to accomplish the task.

Please see inline documentation in @file{src/provider/driver.py} for
more information about the class and its methods and
@file{src/provider/festival.py} for an example.

@node Other tools,  , RetrievalSocket (Python), Drivers in Python
@subsection Other tools (Python)

@itemize
@item
The @code{main_loop} function creates a global logger (with output to
stderr as defined by the Driver guidelines). You can access it via
@code{driver.log.}. For example @code{driver.log.debug(``Hello world'')}

@item 
The @code{main_loop} registers its own callback via
@code{DriverCore.register_callback()} which reports all events via the
standardiz TTS API text protocol mechanism. If your driver implements
the playback method (handles playback itself instead of retrieving the
audio data), you should implement the @code{register_callback()} method
so that your provider registers the correct callback reporting function
at start. Your implementation of @code{DriverCore} is then responsible
to call this callback function on receiving every callback/event.
@end itemize

@node Drivers in C,  , Drivers in Python, Device Driver Implementation
@section Drivers in C

The C library and driver skeleton have not been implemented yet, they
are planned for very near future however.

@node TTS API Implementations,  , Device Driver Implementation, Top
@chapter TTS API Implementations

@menu
* Basic Usage of TTS API::      
* Text Protocol TTS API::       
* Python TTS API::              
@end menu

@node Basic Usage of TTS API, Text Protocol TTS API, TTS API Implementations, TTS API Implementations
@section Basic Usage of TTS API

@menu
* Understanding the API::       
* Initializing and closing a connection::  
* Parameter settings::          
* Speaking and audio retrieval::  
* Callbacks and events::        
* Serialized and simultaneous speech::  
@end menu

@node Understanding the API, Initializing and closing a connection, Basic Usage of TTS API, Basic Usage of TTS API
@subsection Understanding the API

The set of functions available in TTS API Provider, called TTS API, is
defined in a general way at
@url{http://www.freebsoft.org/doc/tts-api/tts-api.html}. We highly
recommend you to study this document carefully before proceeding
further. The interface itself has various implementations. Currently,
there is the TCP text protocol implementation and a python library
implementation. These implementations of the interface differ in the
coding syntax, in the way how functions are called and in the parameter
types. They however should not differ in the functionality provided, so
your best and most accurate guide to the exact meaning of the functions
provided is the description of TTS API itself mentioned above, to which
the various implementations must conform.

Bellow follows a brief overview of the API and some examples of its
proper usage.

@node Initializing and closing a connection, Parameter settings, Understanding the API, Basic Usage of TTS API
@subsection Initializing and closing a connection

TTS API does not require any @code{init} command at the beginning of
each session. Each connection becomes fully operational directly after
connecting on the given socket or creating the appropriate object
according to the communication method in use. When some kind of an
@code{init()} function is necessary for a given API, this is mentioned
in the API documentation.

At the end of each session, client program should call the
@code{close()} function to notify TTS API Provider about session
termination and to close the socket/connection.

@node Parameter settings, Speaking and audio retrieval, Initializing and closing a connection, Basic Usage of TTS API
@subsection Parameter settings

TTS API allows the controlling application to set various speech and controll
parameters. Please see @url{http://www.freebsoft.org/doc/tts-api/tts-api.html#Parameter-Settings}
for a detailed overview.

@node Speaking and audio retrieval, Callbacks and events, Parameter settings, Basic Usage of TTS API
@subsection Speaking and audio retrieval

The client application can request synthesis of text message into audio
stream. Depending on the configuration and synthesizer capabilities,
this audio stream can be played by the synthesizer, by the TTS API
Provider audio subsystem or retrievaed to the client application for
further processing.

Please read
@url{http://www.freebsoft.org/doc/tts-api/tts-api.html#Speech-Synthesis-Commands}
for information about the available speech synthesis commands. If you are interested
in audio retrieval, please also read @url{http://www.freebsoft.org/doc/tts-api/tts-api.html#Audio-Retrieval}.

@node Callbacks and events, Serialized and simultaneous speech, Speaking and audio retrieval, Basic Usage of TTS API
@subsection Callbacks and events

It is essential for proper synchronization in client application and for
further sound processing that the synthesized audio stream is
accompanied with marking information about the former text (sentence and
word boundaries). In case playback of the audio stream is done on the
TTS API Provider side, it is also necessary that some kind of callbacks
is provided so that the client application knows when speech is started
or stopped. Both of these mechanisms are supported by the TTS API
Provider.

The mechanism of reporting this information differs based on whether
playback or audio retrieval is requested. In case of audio retrieval,
the information about various events and their timing in the given audio
stream is sent in a well defined format along with the audio data.  On
the other side, if playback is requested, the events are reported in a
form of callbacks at the time when they are reached by the audio
playback. The exact mechanism may differ according to the API
implementation.

For further information about events in audio retrieval mode,
please see @url{http://www.freebsoft.org/doc/tts-api/tts-api.html#Audio-Retrieval}.

For further information about in-playback callbacks, please see
@url{http://www.freebsoft.org/doc/tts-api/tts-api.html#Event-Callbacks}
and read the documentation specific to the API implementation you use to
learn about the exact mechanism.

@node Serialized and simultaneous speech,  , Callbacks and events, Basic Usage of TTS API
@subsection Serialized and simultaneous speech

Where there are more than one message to be synthesized and played, the
client application may want to achieve either serialized or simultanous
speech, or a combination of them. Serialized speech means that the
messages are spoken one after another without any overlaps, while in
simultanous speech messages are spoken all at the same time. Both
approaches might be useful in certain situations.

TTS API is a low-level interface and for this reason, it doesn't attempt
to solve the synchronization and playback timing of messages. The client
application needs to take care of that.  Nor TTS API Provider connection
nor the API itself is designed to process more than one synthesis
request at a time and such attempts will be rejected.

Thus if the client application wants to synthesize/ speak two or more
messages in parallel, it must open the corresponding number of
independent connections. Each connection to TTS API Provider gets in
turn its own independent connection to the synthesizer (or its own
instance of the synthesizer), so that it is able to fulfill synthesis
requests really in parallel.

When serialized speech (in other words, one message after another) is
desired, the calling program must ensure this using callbacks. A new
synthesis request can only be sent after the message_end callback is
delivered to the program.

@node Text Protocol TTS API, Python TTS API, Basic Usage of TTS API, TTS API Implementations
@section Text Protocol TTS API

This section documents the text protocol in use for communication over
sockets, pipes and other channels where serialized textual protocol is a
convenient interface.

In the protocol description bellow, accent is put on form.  The exact
expected behavior of all the commands and the exact meaning of the
arguments is described in TTS API specifications available from
@url{http://www.freebsoft.org/doc/tts-api/} and is not repeated in
this document. All commands or functions and their arguments have
an identical or very similar name to those in the original TTS API
specifications.

@menu
* General Rules (text protocol)::  
* Return Codes::                
* Driver Discovery (text protocol)::  
* Voice Discovery::             
* Speech Synthesis Commands (text protocol)::  
* Speech Control Commands (text protocol)::  
* Parameter Settings (text protocol)::  
* Event Callbacks (text protocol)::  
* Other Commands (text protocol)::  
@end menu

@node General Rules (text protocol), Return Codes, Text Protocol TTS API, Text Protocol TTS API
@subsection General Rules (text protocol)

The text protocol version of TTS API is defined as a set
of text commands in the usual manner for common Internet
protocols. All the characters are encoded using the UTF-8
encoding.

Each command, unless specified otherwise, consists of exactly
one line.  The line is sent in the following format:

@example
@var{command} @var{arg} ...
@end example

where @var{command} is a case insensitive command name and @var{arg}s
are its arguments separated by spaces.  The command arguments which
come from a defined set of values are case insensitive as well.  The
number of arguments is dependent on the particular command and there
can be commands having no arguments.

All input and output lines must be ended with a pair of
carriage return and line feed characters, in that order.

A connection is preferably closed by issuing the @code{QUIT}
command, see @ref{Other Commands (text protocol)}.

The protocol defined here is synchronous --- you send commands and
only after a complete response arrives back are you allowed to send
the next command. The only exceptions to synchronous communication are
event and index mark notifications sent by the server in order to
inform the client about a task in progress. Such notifications (but
only if requested) are sent asynchronously to the connection.

Usually, the connection remains open during the whole run of the
particular client application.  If you close the connection and open
it again, you must set all the previously set parameters again,
session parameters are not stored between connections.

Replies have the following format:

@example
@var{ccc}-line 1
@var{ccc}-line 2
...
@var{ccc}-line @var{n}-1
@var{ddd} line @var{n}
@end example

where @var{n} is a positive integer, and @var{ccc} and @var{ddd} are
three-digit long numeric codes identifying the result of the command.
The last line determines the overall result of the command. The result
code is followed by an English message describing the result of the
action in a human readable form.

@node Return Codes, Driver Discovery (text protocol), General Rules (text protocol), Text Protocol TTS API
@subsection Return Codes

Each line of the output starts with a three-digit numeric code of
the form @var{NXX} where @var{N} determines the result group and
@var{xx} denotes the finer classification of the result.

The following result groups are defined:

@table @code
@item 1xx
Informative response --- general information about the protocol, help
messages.

@item 2xx
Operation was completely successful.

@item 3xx
Server side error, problem on the server side or in the driver.
@table @code
@item 300 UNKNOWN ERROR
Unknown error.
@item 301 NOT SUPPORTED BY DRIVER
Not supported by the driver.
@item 302 NOT SUPPORTED BY SERVER
Not supported by the server (implementation incomplete).
@item 303 DRIVER ACCESS DENIED
Cannot access driver.
@item 304 INTERNAL ERROR
Internal error in server.
@end table

@item 4xx
Client error, invalid arguments or parameters received,
invalid commands syntax, unparseable input.
@table @code

@item 400 INVALID COMMAND
Invalid command, wrong formating of parameters etc.
@item 401 INVALID ARGUMENT
Invalid command argument value given
@item 402 MISSING ARGUMENT
Missing mandatory command argument.
@item 403 INVALID PARAMETER
Trying to set invalid parameter.
@item 404 ENCODING ERROR
Invalid UTF-8 encoding.
@end table

@item 7xx
Events and index marks notifications.
@table @code
@item 701
Message event.
@item 702
Sentence or word event.
@item 703
Index mark event.
@end table
@end table

Result groups @var{1xx} and @var{2xx} correspond to successful
actions, groups to @var{3xx} to @var{5xx} unsuccessful actions.  Only
the groups defined here may be returned in a valid TTS API connection.

Currently, for return codes in the range @code{100}--@code{299} and
@code{302}--@code{399}, only the meaning of the first digit of the
result code is defined.  The last two digits are insignificant and can
be of any value.  Clients shouldn't rely on the unspecified digits in
any way.

However, the return codes in the range @code{700}--@code{800},
reserved for events notification, are well defined in the appropriate
section of the documentation and client applications can rely on
them.

In the future, these return codes should be fixed so that clients can
rely on them.

@node Driver Discovery (text protocol), Voice Discovery, Return Codes, Text Protocol TTS API
@subsection Driver Discovery (text protocol)

@table @code

@item LIST DRIVERS

Lists the available drivers.

The reply contains several lines of the following form, each one for a
different driver.

@example
201-@var{driver-id} "@var{synthesizer-name}" "@var{synthesizer-version}" "@var{driver-version}"
@end example

Example of usage:
@example
LIST DRIVERS
201-festival "Festival Speech Synthesis System" "1.94beta" "1.2"
201-flite "Festival Lite" "1.2" "1.1"
201 OK LIST SENT
@end example

@item DRIVER CAPABILITIES @var{driver-id}

Return information about the capabilities of the given driver.

The reply takes the following form. Each of the lines must be present
in the following order and carry one of the specified values.  @{a|b@}
means either a or b (but not both) is possible, while [a,b,c] means a,
b, c or any subset where items are separated by spaces.

@example
202-can_list_voices @{@code{true}|@code{false}@}
202-can_set_voice_by_properties @{@code{true}|@code{false}@}
202-can_get_current_voice @{@code{true}|@code{false}@}    
202-rate_settings [@code{absolute}, @code{relative}]
202-can_get_default_rate @{@code{true}|@code{false}@}
202-pitch_settings [@code{absolute}, @code{relative}]
202-can_get_default_pitch @{@code{true}|@code{false}@}
202-pitch_range_settings [@code{absolute}, @code{relative}]
202-can_get_pitch_range_default @{@code{true}|@code{false}@}
202-volume_settings [@code{absolute}, @code{relative}]
202-can_get_volume_default @{@code{true}|@code{false}@}
202-punctuation_modes [@code{all}, @code{none}, @code{some}]
202-can_set_punctuation_detail @{@code{true}|@code{false}@}
202-capital_letters_modes [@code{spelling}, @code{icon}, @code{pitch}]
202-can_set_number_grouping @{@code{true}|@code{false}@}
202-can_say_text_from_position @{@code{true}|@code{false}@}
202-can_say_char @{@code{true}|@code{false}@}
202-can_say_key @{@code{true}|@code{false}@}
202-can_say_icon @{@code{true}|@code{false}@}
202-can_set_dictionary @{@code{true}|@code{false}@}
202-audio_methods [@code{playback}, @code{retrieval}]
202-events [@code{by_sentences}, @code{by_words}, @code{by_index_marks}]
202-performance_level @{@code{none}|@code{good}|@code{excelent}@}
202-can_defer_message @{@code{true}|@code{false}@}
202-can_parse_ssml @{@code{true}|@code{false}@}
202-supports_multilingual_utterances @{@code{true}|@code{false}@}
202 OK DRIVER CAPABILITIES SENT
@end example

Example of usage (incomplete reply indicated by '[...]')

@example
DRIVER CAPABILITIES festival
202-can_list_voices @code{true}
202-can_set_voice_by_properties @code{true}
202-can_get_current_voice @code{true}    
202-rate_settings @code{relative} @code{absolute}
[...]
202-honors_performance_guidelines @code{excelent}
202-can_defer_message @code{false}
202-can_parse_ssml @code{true}
202-supports_multilingual_utterances @code{false}
202 OK DRIVER CAPABILITIES SENT
@end example

@end table

@node Voice Discovery, Speech Synthesis Commands (text protocol), Driver Discovery (text protocol), Text Protocol TTS API
@subsection Voice Discovery

@table @code

@anchor{LIST VOICES}
@item LIST VOICES @var{driver-id}

List voices available for a given driver.

The reply contains zero or more lines of the following form.
@example
203-"@var{name}" @var{language} "@var{dialect}" @{@code{MALE}|@code{FEMALE}@} @var{age}
@end example

Example usage:
@example
LIST VOICES festival
201-"kal" en nil MALE 30
201-"ked" en nil MALE 30
201-"czech_ph" cs nil MALE 30
201-"el_diphone" es nil MALE 48
201-"lp_diphone" it nil MALE 30
201-"pc_diphone" it nil FEMALE 30
201-OK LIST SENT
@end example
@end table

@node Speech Synthesis Commands (text protocol), Speech Control Commands (text protocol), Voice Discovery, Text Protocol TTS API
@subsection Speech Synthesis Commands (text protocol)

Commands listed in this section are actual request for synthesis (and
possibly playback) of a textual or sound message.

@table @code
@anchor{SAY TEXT}
@item SAY TEXT @var{format}

Start receiving a text message and synthesize it.  After sending a
reply to the command, the server waits for the text of the message.
The text can spread over any number of lines and is finished by an end
of line marker followed by the line containing the single character
@code{.} (dot).  Thus the complete character sequence closing the
input text is @code{CR LF . CR LF}.  If any line within the sent text
starts with a dot, an extra dot is prepended before it.

During reception of the text message, server doesn't send responses
for the lines sent.  The response line is sent only immediately after
the @code{SPEAK} command and after receiving the closing dot
line. Server can start input processing or speech synthesis as soon as
a sufficient amount of the text arrives; it generally needn't (but
may) wait until the end of data marker is received.

There is no explicit upper limit on the size of the text, but the
server administrator may set one in the configuration or the limit can
be enforced by available system resources.  If the limit is exceeded,
the whole text is accepted, but the excess is ignored and an error
response code is returned after processing the final dot line.

The content of the message can be either a plain text or a SSML
(Speech Synthesis Markup Language) text according to the @var{format}
argument. @var{format} can be either @code{SSML} or @code{PLAIN}.

Position where to start synthesis is specified as a non-negative
number @var{position} and the type of the event @var{position_type} as
specified in TTS API with one of the following values:
@code{MESSAGE_BEGIN}, @code{MESSAGE_END}, @code{SENTENCE_BEGIN},
@code{SENTENCE_END}, @code{WORD_BEGIN}, @code{WORD_END}.

The reply for the @code{SAY} command has the form

@example
204 OK RECEIVING DATA
@end example

and the reply to the end of text marker @code{CR LF . CR LF}
completing the whole composed command is

@example
203-@var{message-id}
204 OK MESSAGE RECEIVED
@end example

where @var{message-id} is a positive number representing the unique
message identification.

Example usage:
@example
SAY TEXT @emph{PLAIN}
203 OK RECEIVING DATA
Hello world!
.
204-67
204 OK MESSAGE RECEIVED
@end example

@anchor{SAY TEXT FROM POSITION}
@item SAY TEXT FROM POSITION @var{position} @var{position_type}

Same as (@pxref{SAY TEXT}) except synthesis is started from a given
event of type @var{position_type} on @var{position}
specified as a positive number.

@var{position_type} is one of @code{SENTENCE_BEGIN}, @code{SENTENCE_END},
@code{WORD_BEGIN}, @code{WORD_END}.

Example usage:
@example
SPEAK @emph{PLAIN} FROM POSITION @emph{2} @emph{WORD_BEGIN} 
203 OK RECEIVING DATA
Hello, world.
204-68
204 OK MESSAGE RECEIVED
@end example

@anchor{SAY TEXT FROM CHARACTER}
@item SAY TEXT @var{format} FROM CHARACTER @var{character_position}

Same as (@pxref{SAY TEXT}) except synthesis is started from a given
character position @var{character_position} specified as a non-negative
number.

Example usage:
@example
SPEAK @emph{PLAIN} FROM CHARACTER @emph{7}
203 OK RECEIVING DATA
Hello, world.
204-69
204 OK MESSAGE RECEIVED
@end example

@anchor{SAY TEXT FROM INDEX MARK}
@item SAY TEXT @var{format} FROM INDEX MARK "@var{index_mark}"

Same as (@pxref{SAY TEXT}) except synthesis is started from a
client supplied index mark @var{index_mark}.

Example usage:
@example
SPEAK @emph{SSML} FROM INDEX_MARK "test"
203 OK RECEIVING DATA
<speak>
Hello, <mark name="test">world.
</speak>
204-70
204 OK MESSAGE RECEIVED
@end example

@anchor{SAY DEFERRED}
@item SAY DEFERRED @var{message-id}

Similar to @pxref{SAY TEXT} except this commands
accepts no text.

@item SAY DEFERRED @var{message-id} FROM POSITION @var{position} @var{position_type}

Similar to @pxref{SAY TEXT FROM POSITION} except this commands
accepts no text.

@item SAY DEFERRED @var{message-id} FROM CHARACTER @var{character_position}

Similar to @pxref{SAY TEXT FROM CHARACTER} except this commands
accepts no text.

@item SAY DEFERRED @var{message-id} FROM INDEX MARK "@var{index_mark}"

Similar to @pxref{SAY TEXT FROM INDEX MARK} except this commands
accepts no text.

@anchor{SAY CHAR}
@item SAY CHAR @var{char}

Speak letter @var{char}.  @var{char} can be any character
representable by the UTF-8 encoding. The only exception is the
character space (@code{ }); that can't be sent directly. In this case,
a string @code{space} must be sent instead.

Example usage:
@example
SAY CHAR e
204-71
204 OK MESSAGE RECEIVED

SAY CHAR \
204-72
204 OK MESSAGE RECEIVED

SAY CHAR space
204-73
204 OK MESSAGE RECEIVED

SAY CHAR &
204-74
204 OK MESSAGE RECEIVED
@end example

This command is intended to be used for speaking single letters,
e.g. when reading a character under cursor or when spelling words.

@anchor{SAY KEY}
@item SAY KEY @var{key_name}

Example usage:
@example
SAY KEY shift_A
204-75
204 OK MESSAGE RECEIVED
@end example

Accept a key identified by @var{key_name} as message.  The command is
intended to be used for speaking keys pressed by the user.

@anchor{SAY ICON}
@item SAY ICON @var{icon_name}

Accept a general sound icon identified by @var{icon_name}.

Example usage:
@example
SAY ICON new-line
204-76
204 OK MESSAGE RECEIVED
@end example

@end table

@node Speech Control Commands (text protocol), Parameter Settings (text protocol), Speech Synthesis Commands (text protocol), Text Protocol TTS API
@subsection Speech Control Commands (text protocol)

@table @code
@item CANCEL

Immediately stop synthesis and audio output of the current message,
throw away all the data about this message and prepare the synthesizer
to receive a new message.

Example usage:
@example
CANCEL
209 OK CANCELED
@end example

@item DEFER

If synthesis and/or audio output are in progress, immediately stop
them. Keep the original text and as much data (possibly also audio) as
is needed to resume the message later via @code{SAY DEFERRED}.

Reply has the following form
@example
209-@var{message_id}
209 OK DEFERRED
@end example

where @var{message_id} is a unique positive number as defined in
TTS API.


Example usage:
@example
DEFER
209-47
209 OK DEFERRED
@end example

@item DISCARD @var{message_id}

Discards a previously deffered message.

Example usage:
@example
DISCARD 47
210 OK MESSAGE DISCARDED
@end example

@end table

@node Parameter Settings (text protocol), Event Callbacks (text protocol), Speech Control Commands (text protocol), Text Protocol TTS API
@subsection Parameter Settings (text protocol)

All settings except for driver selection only have effect
until the driver is changed.

Success return codes for all SET commands are
@example
211 OK PARAMETER SET
@end example

@menu
* Driver Selection and Parameters (text protocol)::  
* Voice Selection (text protocol)::  
* Prosody Parameters (text protocol)::  
* Style Parameters (text protocol)::  
* Dictionaries::                
* Audio Settings::              
@end menu

@node Driver Selection and Parameters (text protocol), Voice Selection (text protocol), Parameter Settings (text protocol), Parameter Settings (text protocol)
@subsubsection Driver Selection and Parameters (text protocol)

@table @code
@item SET DRIVER @var{driver_id}
Set the synthesis driver.

Example usage:
@example
SET DRIVER festival
211 OK PARAMETER SET
@end example
@end table

@node Voice Selection (text protocol), Prosody Parameters (text protocol), Driver Selection and Parameters (text protocol), Parameter Settings (text protocol)
@subsubsection Voice Selection (text protocol)

@table @code

@item SET VOICE BY NAME "@var{voice_name}"
Set voice by name for the synthesis driver in use.

Example usage:
@example
SET VOICE BY NAME "kal"
211 OK PARAMETER SET
@end example

@item SET VOICE BY PROPERTIES @var{language} "@var{dialect}" @var{gender} @var{age} @var{variant}
Set voice by the given properties.

Example usage:
@example
SET VOICE BY PROPERTIES cs nil FEMALE nil 0
211 OK PARAMETER SET
@end example

@item GET CURRENT VOICE

Return information about the currently used voice. The output
contains exactly two lines of this form:

@example
212-"@var{name}" @var{language} "@var{dialect}" @{@code{MALE}|@code{FEMALE}@} @var{age}
212 OK VOICE DESCRIPTION SENT
@end example

Example usage:
@example
GET CURRENT VOICE
212-"kal" en nil MALE 30
203-OK LIST OF VOICES SENT
@end example

@end table

@node Prosody Parameters (text protocol), Style Parameters (text protocol), Voice Selection (text protocol), Parameter Settings (text protocol)
@subsubsection Prosody Parameters (text protocol)

@table @code

@anchor{SET RATE}
@item SET @{@emph{RELATIVE}|@emph{ABSOLUTE}@} RATE @var{rate}

Set relative or absolute rate. @var{rate} is a positive or negative
number representing percents for relative changes, it is a positive
number representing words per minute for absolute changes.

Example usage
@example
SET RELATIVE RATE +300
211 OK PARAMETER SET

SET RELATIVE RATE -20
211 OK PARAMETER SET

SET RELATIVE RATE 150
211 OK PARAMETER SET
@end example

@item GET DEFAULT ABSOLUTE RATE

Get absolute value of default rate for the voice in use.

Reply is in the form:
@example
213-@var{absolute_rate}
213-OK ABSOLUTE RATE IN WPM SENT
@end example

where @var{absolute_rate} is a positive number representing
the rate in words per minute.

@item SET @{@emph{RELATIVE}|@emph{ABSOLUTE}@} PITCH @var{pitch}

Set relative or absolute rate. @var{pitch} is a positive or negative
number representing percents for relative changes, it is a positive
number representing Hertzs for absolute changes.

Examples are analogous to those for @pxref{SET RATE}

@item GET DEFAULT ABSOLUTE PITCH

Get default value of absolute pitch for the voice in use.

Reply is in the form:
@example
214-@var{pitch}
214-OK ABSOLUTE PITCH IN HZ SENT
@end example

where @var{pitch} is a positive number representing
the pitch in Hertzs.

@item SET @{@emph{RELATIVE}|@emph{ABSOLUTE}@} PITCH_RANGE @var{pitch_range}

Set relative or absolute pitch range. @var{pitch_range} is a positive or
negative number representing percents for relative changes, it is a
positive number representing Hertzs absolute changes.

Examples are analogous to those for @pxref{SET RATE}.

@item SET @{@emph{RELATIVE}|@emph{ABSOLUTE}@} VOLUME @var{volume}

Set relative or absolute volume. @var{volume} is a positive or negative
number representing percents for relative changes, it is a positive
number between 0 (silence) and 100 (max volume) for absolute changes.

Examples are analogous to those for @pxref{SET RATE}.

@item GET DEFAULT ABSOLUTE VOLUME

Get absolute value of default volume for the voice in use.

Reply is in the form:
@example
215-@var{pitch}
215-OK ABSOLUTE VOLUME IN DB SENT
@end example

where @var{volume} is a positive number.

@end table

@node Style Parameters (text protocol), Dictionaries, Prosody Parameters (text protocol), Parameter Settings (text protocol)
@subsubsection Style Parameters (text protocol)

@table @code
@item SET PUNCTUATION MODE @var{punctuation-mode}

Set punctuation mode to @var{punctuation-mode}. Allowed
values are @code{NONE}, @code{ALL}, @code{SOME}.

Example usage:
@example
SET PUNCTUATION MODE ALL
211 OK PARAMETER SET
@end example

@item SET PUNCTUATION DETAIL @var{detail}

Set the detail for punctuation reading when punctuation mode
is set to @code{SOME}. Detail is a string enumerating all
punctuation characters that should be explicitly pronounced.
The string must not contain any whitespace characters.

Example usage:
@example
SET PUNCTUATION DETAIL ?!.#
211 OK PARAMETER SET
@end example

@item SET CAPITAL LETTERS MODE @var{cap-let-mode}

Set capital letters reading mode. Allowed values
for the @var{cap-let-mode} parameter are: @code{NO},
@code{SPELLING}, @code{ICON}, @code{PITCH}.

Example usage:
@example
SET CAPITAL LETTERS MODE ICON
211 OK PARAMETER SET
@end example

@item SET NUMBER GROUPING @var{grouping}

Set grouping of digits for reading numbers. The parameter
@var{grouping} is a non-negative number.

@end table

@node Dictionaries, Audio Settings, Style Parameters (text protocol), Parameter Settings (text protocol)
@subsubsection Dictionaries

@node Audio Settings,  , Dictionaries, Parameter Settings (text protocol)
@subsubsection Audio Settings

@table @code

@item SET AUDIO OUTPUT @var{method}

Sets audio output method. Available values of the @var{method}
argument are @code{PLAYBACK} and @code{RETRIEVAL}.

Example usage:
@example
SET AUDIO OUTPUT PLAYBACK
211 OK PARAMETER SET
@end example

@item SET AUDIO RETRIEVAL DESTINATION @var{host} @var{port}

Sets destination for audio retrieval. @var{host} is the IP address of
the machine where audio data should be delivered.  The IP address is
written as groups of three digits separated by dots. @var{port}
is a positive number of the desired port.

Example usage:
@example
SET AUDIO RETRIEVAL DESTINATION 127.0.0.1 1315
211 OK PARAMETER SET
@end example

@end table

@node Event Callbacks (text protocol), Other Commands (text protocol), Parameter Settings (text protocol), Text Protocol TTS API
@subsection Event Callbacks (text protocol)

Event are reported on the main connection asynchronously and only if
the audio output method is set to @code{PLAYBACK}.  (If output method
is set to @code{RETRIEVAL}, information about events reached is sent
together with the audio data on the appropriate side channel).

Asynchronous nature of the event reports means such messages in the
protocol are not a result of a command being sent by the client and
may come at any time after a request for speaking (@code{SAY}) is
sent.  Such notifications can be sent even the @code{CANCEL} or
@code{DEFER} command is issued.

Information about each event is sent in this form:

@itemize
@item Message Events

@example
701-@var{type} @var{n} @var{pos_text}
701 MESSAGE EVENT
@end example

@item Sentence and Word Events

@example
702-@var{type} @var{n} @var{pos_text}
702 SENTENCE OR WORD EVENT
@end example

@item Index Mark Events

@example
703-@var{event-type} "@var{name}" @var{pos-text}
703 EVENT SENT
@end example
@end itemize

the exact meaning and format of the parameters is explained in TTS API
specifications under section Audio Retrieval. 

@node Other Commands (text protocol),  , Event Callbacks (text protocol), Text Protocol TTS API
@subsection Other Commands (text protocol)

@table @code
@item QUIT
Close the connection. No reply is sent and the connection is closed on
server side.

Example usage:
@example
QUIT
@end example

@item HELP
Print a short list of all available commands as a multi-line message.

The following format is used for reply:
@example
800-line 1
800-line 2
800 HELP SENT
@end example

Example usage:
@example
HELP
800-SAY
800-[...]
800-CANCEL
800-[...]
800-HELP
800 HELP SENT
@end example
@end table


@page
@node Python TTS API,  , Text Protocol TTS API, TTS API Implementations
@section Python TTS API

Python API is documented through docstrings and embedded comments.
Please see @file{src/ttsapi/client.py} in the source tree. This
documentation however includes only facts specific for the python
implementation and only a very brief description of the functionality
provided by the offered methods.

Please read first @pxref{Basic Usage of TTS API} for a general overview
of how to use the API.

Please also refer to
@url{http://www.freebsoft.org/doc/tts-api/tts-api.html} for the exact
general description of the functionality provided by the API functions and
for the description of the event/callback and playback/audio retrieval
mechanisms in use.

@bye
