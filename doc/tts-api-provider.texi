cvs-st  
\input texinfo   @c -*-texinfo-*-
@c %**start of header
@setfilename tts-api-provider.info
@settitle TTS API Provider
@finalout
@c @setchapternewpage odd
@c %**end of header

@copying
Copyright @copyright{} 2006, 2007 Brailcom, o.p.s.
All rights reserved.

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.2 or
any later version published by the Free Software Foundation; with no
Invariant Sections, with no Front-Cover Texts and no Back-Cover Texts.
A copy of the license is included in the section entitled ``GNU Free
Documentation License.''
@end quotation

A copy of the license is included in the section entitled ``GNU
General Public License''
@end copying

@c @set version 2006-03-09

@c Directory, keywords
@dircategory Sound
@dircategory Development
@dircategory Accessibility

@direntry
* TTS API Provider: (tts-api).    TTS API Provider
@end direntry

@c Title page for printed version
@titlepage
@title TTS API Provider 

@author Hynek Hanke, Brailcom <@email{hanke@@brailcom.org}>
@author Jan Buchal, Brailcom <@email{buchal@@brailcom.org}>
@author Gary Cramblitt, KDE <@email{garycramblitt@@comcast.net}> 

@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage
@contents

@c Title page for INFO
@ifnottex
@node Top, Introduction, (dir), (dir)
@top TTS API Provider
@insertcopying
@end ifnottex

@menu
* Introduction::                
* Design::                      
* Server Implementation::       
* TTS API Implementations::     
@end menu

@node Introduction, Design, Top, Top
@chapter Introduction

TTS API Provider is a system service providing applications with
low-level access to various synthesizers via TTS API (See TTS API
specification, @uref{http://www.freebsoft.org/tts-api}). It manages
the synthesizers available on the system and provides a unified
interface to them.

This API was developed in cooperation between the biggest Free
Software accessibility projects at that time (Gnome Accessibility
Project, KDE Accessibility, Free-b-Soft and others). It is made
available publicly and separately in the hope to unify our efforts,
revise the speech output architecture and put it on solid, well
designed, well documented and de-facto standardized grounds. Its
target is on accessibility, however we believe it is powerful enough
to be useful in other areas too where speech synthesis is useful.

Our publishing of the API and making it available on the system for
easy use should however not be seen as an encouragement for developers
to use this low-level API directly! Most applications, especially
accessibility applications, should never contact this low-level API
directly. They should use a high-level API such as one of the Speech
Dispatchers APIs, Gnome Speech API or KTTS API doing the necessary
coordination of messages from various applications. To put it simple,
one should only use TTS API Provider directly and fully if he is sure
he is authorized to take complete control over all speech synthesis
audio output on the system. As mentioned, this is mostly never the
case of ordinary applications. In the audio world, the issue could be
compared to applications taking control over the /dev/dsp device
(under OSS) or intentionally bypassing the mixer (under ALSA) and thus
blocking others. @footnote{While sound output for various concurrent
speech streams is not a problem any longer, if it is done without any
attempt at coordination and control, the result will likely be that
the user can't understand any of the streams.}  An exception to this
rule are applications on embedded systems, highly specialized
applications like telephony servers, speech synthesis research and
development applications and applications who only retrieve the
synthesized audio samples but do not play them on the sound card
(e.g. a text2wav converter).  If in doubt, please contact us.

@node Design, Server Implementation, Introduction, Top
@chapter Design

TTS API Provider is composed of four independent parts.  The
@emph{provider itself}, running on the system and interfacing
applications with speech synthesizers and doing the necessary
emulations, the various @emph{drivers} that translate the APIs of the
synthesizers into TTS API, @emph{driver template library} to help with
developement of drivers and @emph{convenience libraries} which provide
easy access to TTS API from various languages.

@menu
* General Design::              
* TTS API Provider (core)::     
* Drivers::                     
* Driver Template Library::     
* Convenience Libraries for Applications::  
@end menu

@node General Design, TTS API Provider (core), Design, Design
@section General Design

The intended middle-term design, as also described in other sections
in this chapter, is demonstrated on the following picture. Please keep
in mind the picture was not meant to be exhaustive and only contains
the main ideas and some examples.

@image{figures/architecture,155mm,,TTS API Provider architecture}

Such an architecture is not ideal, however. The optimal future design
is demonstrated on the picture bellow. Most important, TTS API
Provider should not have to take care of directly handling audio
devices and doing its own audio output. This is a task unrelated to
the Text-to-Speech process, necessary for many other applications
outside the domain of speech synthesis and accessibility, and as such
would best be left to an independent component. Only because currently
we do not know of any general Free Software audio component that could
handle our needs, we will temporarily continue to provide our own
basic audio output.

@image{figures/architecture-future,155mm,,TTS API Provider architecture in the future}

Also, ideally, audio should not be transported through the engine
driver, but could be directed from the synthesizer itself directly to
the destination, lowering the latency and transport overhead, as
is illustrated on the picture in case of Festival.

@node TTS API Provider (core), Drivers, General Design, Design
@section TTS API Provider (core)

@heading Functionality

@itemize
    @item manage all drivers
    @item emulate necessary functionality not supported by the drivers
    @item provide interface to applications
@end itemize

@heading Implementation

@itemize
@item License: GNU GPL
@item Language: Python
@item Dependencies: Python
@end itemize

TTS API Provider will be a separate process for the following
reasons:

@itemize
@item
There will be only one instance of it running on the system at a given
time, which simplifies things like rereading configuration after
configuration change, maintaining context on simple non-context
synthesizers (!), solving of conflicts in access to hardware
synthesizers. It will make it possible not to lunch unnecessarily many
drivers for one synthesizer (!).

@item
Applications won't have compile dependency on TTS API Provider.

@item
Applications won't be affected by TTS API Provider stability.

@item
The language of implementation of TTS API Provider is not important
for the applications.

@item
Problems with TTS API Provider will be easier to diagnose for the user
and its debugging will be easier for the developers.

@item
Communication can be led over network.
@end itemize

TTS API Provider communication layer will provide a TCP version of TTS
API. This TCP inter-process communication will be wrapped in
convenience libraries (4) for easy use in the application. Care will
be taken to avoid dependency on this particular communication method
so that in the future, other IPC methods like Corba or DBUS can be
added if necessary.

TTS API Provider will automatically launch available engine
drivers. In order to achieve context independency of clients, to allow
more clients to perform synthesis at once and to keep the synthesizer
drivers simple (not require them to explicitly handle various
clients), it might sometimes be necessary to have several instances of
a driver running to serve the various clients.

TTS API Provider will temporarily handle audio output if
necessary. Audio output code should not be a part of TTS API Provider,
but currently no audio output framework is available on the Free
Software platform which would fit our needs. The audio handling part
is to be removed as soon as such a framework is available.

TTS API Provider will emulate the necessary functionality that is
reported by the synthesizer drivers through TTS API as
non-available. The most important examples are: SSML to plain-text
conversion, context switching and breaking of long text into smaller
chunks.

TTS API Provider will provide the defer() and say_deferred() mechanism
for all synthesizers (maintaining the necessary heap of messages for
synthesizers who do not support it). This will significantly release
implementation burden on the applications.

@node Drivers, Driver Template Library, TTS API Provider (core), Design
@section Drivers

@heading Functionality

@itemize
@item initialization of and communication with synthesizers
@item conversion between TTS API and synthesizer API
@item only emulate functionality where necessary
for conversion between TTS API and synthesizer API
@end itemize

@heading Implementation

@itemize @w{}
@item @emph{License}: various
@item @emph{Language}: various, most often C
@item @emph{Dependencies}: various, driver template library
@end itemize

Drivers will be separate processes as is completely necessary
for legal reasons and for the reasons of stability.

Drivers can be built using the driver template library (3),
although this is not necessary.

Drivers will communicate in the same TCP version of TTS API through
pipes, reading from their standard input and writing to their standard
output.

@node Driver Template Library, Convenience Libraries for Applications, Drivers, Design
@section Driver Template Library

@heading Functionality:
@itemize
@item take care of IPC communication (TTS API + audio socket)
@item provide the necessary infrastructure (threads etc.)
so that the driver author can only implement the necessary TTS
API functions
@item provide tools to make conversion between TTS API and the various
synthesizer APIs easier
@end itemize

@heading Implementation
@itemize @w{}
@item @emph{License}: GNU LGPL
@item @emph{Language}: C (maybe also Python bindings or Python version)
@item @emph{Dependencies}: libc, ?
@end itemize

@node Convenience Libraries for Applications,  , Driver Template Library, Design
@section Convenience Libraries for Applications

@heading Functionality

@itemize
@item expose a simple library version of TTS API and take
care of	IPC communication
@end itemize

@heading Implementation

@itemize @w{}
@item @emph{License}: GNU LGPL
@item @emph{Language}: C, Python
@item @emph{Dependencies}: libc, Python
@end itemize

@node Server Implementation, TTS API Implementations, Design, Top
@chapter Server Implementation

This chapter roughly describes the implementation of TTS API provider,
including the related subsystems (driver templates, audio subsystem
etc.). This chapter should rather be seen more as an introduction
guide for new developers than an exhaustive technical code
documentation.  Please note that this description is not necessarily
up to date. Ultimate documentation for the implementation are the
abundant comments in the source code itself.

@menu
* TTS API Provider Core (implementation)::  
* Audio Subsystem (implementation)::  
* Python Device Driver Template (implementation)::  
@end menu

@node TTS API Provider Core (implementation), Audio Subsystem (implementation), Server Implementation, Server Implementation
@section TTS API Provider core (implementation)

TTS API Provider is a thread-based server. Handling of each client is
done in a separate thread which in turn operates a separate set of
output drivers. This is highly convenient as by a design decision,
there are made no assumptions on interaction between the various
clients.  In other words, the design must allow for multiple clients
handling their synthesis requests and speaking at the same time. This
allows higher level layers using TTS API to do a very sophisticated
message coordination including serialized AND concurent speech, 3D
aural speech from multiple sources etc.

The main server with its daemon functionality (pidfile, signals,
terminal detaching, global state of the server and global audio events
receiver) is implemented in the source file @file{src/server.py}. The
server is currently based on TCP communication and TCP communication
should remain a part of the functionality. However, it is by no means
restricted to TCP communication. @file{src/server.py} can be extended
to include also other means of communication (DBUS, etc.) without
loosing the Provider functionality provided by the underlaying
modules. For such reason, care is taken to distinguish between the
different modes of communication in paramters passed forward even
though currently text-based TCP (or pipes) is the only option.

@heading Connection handling

When a new connection is obtained, a new thread is created running the
@code{serve_client} function found in the same source
file. @code{serve_client} starts a new @code{provider.Provider}
object. The global logging, configuration, audio (subsystem) are
passed to the Provider object on initialization.

A second object of the family @code{ttsapi.server.} is then created to
handle the connection. It is given the new @code{provider.Provider}
object as its parameter. Its method @code{connection.process_input()}
is then being called in a loop. This connection object will process
the input from the communication channel and call the appropriate
communication-mechanism independent method of the object
@code{Provider}. @code{provider.Provider} is then responsible for
providing the TTS API functionality, emulations and communication with
the device drivers. It roughly implements the Python version of TTS API.

@heading Audio Event Delivery Thread

One thread is launched by the TTS API Provider right on its start.  It
is the Audio Event Delivery Thread running as function
@code{audio_event_delivery} implemented in @file{src/server.py}.
This thread listens for all audio events delivered to TTS API Provider
from the audio subsystem and dispatches them to the various
@code{provider.Provider} objects associated with the appropriate
connection to which this audio event belongs.

Please note that it is important not to slide into the temptation of
delivering audio events from the audio subsystem to the provider
objects directly as it is a design decision to eventually split the
audio subsystem and TTS API provider into different servers. (The
idea is to use some global Free Software audio subsystem when one
appears that fulfills the Accessibility Audio Framework Requirements
and drop our own codebase). Once such a transition is achieved, events
will necessarily be delivered into the server as a whole, not directly
to the @code{provider.Provider} instances, so it will only be
necessary to modify the @code{audio_event_delivery} method if this
strict separation is maintained.

For more information about the audio subsystem, please see @xref{Audio
Subsystem (implementation)}.

@heading Provider Object

The @code{Provider} object is implemented in the file
@file{src/provider.py} and implements the core functionality of TTS API
Provider in a client-server communication method independent way. On
initialization, it starts its own set of device driver
processes. Communication with the device drivers is currently led in
the text-based pipe version of TTS API, the same code in
@file{src/ttsapi/server.py} is used as for communication between
clients and provider. Please refer to TTS API definition document,
@xref{Python TTS API}, and the source code itself for description of
the available methods and their function.

With regards to @code{emulation} of missing capabilities in the
drivers: Ideally, all emulation should be done in the provider object
by cooperation with its subsystems whenever the driver reports that a
capability is not available. Generally useful emulations like
character caching, defer, text-substitution (punctuation, capital
letters) and index marking emulation etc. should not be done in the
drivers as this unnecessarily blows their codebase, reduces
readability and necessarily leads to duplication of code. Emulations
that do not emulate TTS API @code{MUST HAVE} functionality must be
configurable.

The provider object recognizes three audio output methods:
@itemize
@item retrieval -- audio data will be retrieved to client application
@item playback -- the synthesizer will play the audio data on speakers
@item emulated_playback -- audio data will be passed to the TTS API Provider
audio subsystem for playback
@end itemize

Methods @code{retrieval} and @code{emulated_playback} are only
available if the device can return the synthesized data to the caller.
For simple hardware synthesizers, only method playback is available.
However, when both playback and retrieval are available by the device
itself and the client requests playback, Provider will use
'emulated_playback' so that we have full controll over the playback
and we do not have to deal with the (usually numerous) bugs in
synthesizers implementation of audio output (device blocking etc.)
according to the TTS API Provider design decisions.

If method @code{emulated_playback} is being used, the @code{say_}
functions need to notify the audio subsystem about the new message
identification and tell it to expect new audio data in its audio data bin.
Also request for playback must be sent whenever necessary. Please see the
method @code{provider._prepare_for_message} in @file{src/provider.py}.

@node Audio Subsystem (implementation), Python Device Driver Template (implementation), TTS API Provider Core (implementation), Server Implementation
@section Audio Subsystem (implementation)



@node Python Device Driver Template (implementation),  , Audio Subsystem (implementation), Server Implementation
@section Python Device Driver Template (implementation)


@node TTS API Implementations,  , Server Implementation, Top
@chapter TTS API Implementations

@menu
* Text Protocol TTS API::       
* Python TTS API::              
@end menu

@node Text Protocol TTS API, Python TTS API, TTS API Implementations, TTS API Implementations
@section Text Protocol TTS API

This section documents the text protocol in use for communication
over sockets, pipes and other channels where serialized textual
protocol is a convenient interface.

In the protocol description bellow, accent is put on form.  The exact
expected behavior of all the commands and the exact meaning of the
arguments is described in TTS API specifications available from
@url{http://www.freebsoft.org/doc/tts-api/} and is not repeated in
this document. All commands or functions and their arguments have
an identical or very similar name to those in the original TTS API
specifications.

@menu
* General Rules (text protocol)::  
* Return Codes::                
* Driver Discovery (text protocol)::  
* Voice Discovery::             
* Speech Synthesis Commands (text protocol)::  
* Speech Control Commands (text protocol)::  
* Parameter Settings (text protocol)::  
* Event Callbacks (text protocol)::  
* Other Commands (text protocol)::  
@end menu

@node General Rules (text protocol), Return Codes, Text Protocol TTS API, Text Protocol TTS API
@subsection General Rules (text protocol)

The text protocol version of TTS API is defined as a set
of text commands in the usual manner for common Internet
protocols. All the characters are encoded using the UTF-8
encoding.

Each command, unless specified otherwise, consists of exactly
one line.  The line is sent in the following format:

@example
@var{command} @var{arg} ...
@end example

where @var{command} is a case insensitive command name and @var{arg}s
are its arguments separated by spaces.  The command arguments which
come from a defined set of values are case insensitive as well.  The
number of arguments is dependent on the particular command and there
can be commands having no arguments.

All input and output lines must be ended with a pair of
carriage return and line feed characters, in that order.

A connection is preferably closed by issuing the @code{QUIT}
command, see @ref{Other Commands (text protocol)}.

The protocol defined here is synchronous --- you send commands and
only after a complete response arrives back are you allowed to send
the next command. The only exceptions to synchronous communication are
event and index mark notifications sent by the server in order to
inform the client about a task in progress. Such notifications (but
only if requested) are sent asynchronously to the connection.

Usually, the connection remains open during the whole run of the
particular client application.  If you close the connection and open
it again, you must set all the previously set parameters again,
session parameters are not stored between connections.

Replies have the following format:

@example
@var{ccc}-line 1
@var{ccc}-line 2
...
@var{ccc}-line @var{n}-1
@var{ddd} line @var{n}
@end example

where @var{n} is a positive integer, and @var{ccc} and @var{ddd} are
three-digit long numeric codes identifying the result of the command.
The last line determines the overall result of the command. The result
code is followed by an English message describing the result of the
action in a human readable form.

@node Return Codes, Driver Discovery (text protocol), General Rules (text protocol), Text Protocol TTS API
@subsection Return Codes

Each line of the output starts with a three-digit numeric code of
the form @var{NXX} where @var{N} determines the result group and
@var{xx} denotes the finer classification of the result.

The following result groups are defined:

@table @code
@item 1xx
Informative response --- general information about the protocol, help
messages.

@item 2xx
Operation was completely successful.

@item 3xx
Server side error, problem on the server side or in the driver.
@table @code
@item 300 UNKNOWN ERROR
Unknown error.
@item 301 NOT SUPPORTED BY DRIVER
Not supported by the driver.
@item 302 NOT SUPPORTED BY SERVER
Not supported by the server (implementation incomplete).
@item 303 DRIVER ACCESS DENIED
Cannot access driver.
@item 304 INTERNAL ERROR
Internal error in server.
@end table

@item 4xx
Client error, invalid arguments or parameters received,
invalid commands syntax, unparseable input.
@table @code

@item 400 INVALID COMMAND
Invalid command, wrong formating of parameters etc.
@item 401 INVALID ARGUMENT
Invalid command argument value given
@item 402 MISSING ARGUMENT
Missing mandatory command argument.
@item 403 INVALID PARAMETER
Trying to set invalid parameter.
@item 404 ENCODING ERROR
Invalid UTF-8 encoding.
@end table

@item 7xx
Events and index marks notifications.
@table @code
@item 701
Message event.
@item 702
Sentence or word event.
@item 703
Index mark event.
@end table
@end table

Result groups @var{1xx} and @var{2xx} correspond to successful
actions, groups to @var{3xx} to @var{5xx} unsuccessful actions.  Only
the groups defined here may be returned in a valid TTS API connection.

Currently, for return codes in the range @code{100}--@code{299} and
@code{302}--@code{399}, only the meaning of the first digit of the
result code is defined.  The last two digits are insignificant and can
be of any value.  Clients shouldn't rely on the unspecified digits in
any way.

However, the return codes in the range @code{700}--@code{800},
reserved for events notification, are well defined in the appropriate
section of the documentation and client applications can rely on
them.

In the future, these return codes should be fixed so that clients can
rely on them.

@node Driver Discovery (text protocol), Voice Discovery, Return Codes, Text Protocol TTS API
@subsection Driver Discovery (text protocol)

@table @code

@item LIST DRIVERS

Lists the available drivers.

The reply contains several lines of the following form, each one for a
different driver.

@example
201-@var{driver-id} "@var{synthesizer-name}" "@var{synthesizer-version}" "@var{driver-version}"
@end example

Example of usage:
@example
LIST DRIVERS
201-festival "Festival Speech Synthesis System" "1.94beta" "1.2"
201-flite "Festival Lite" "1.2" "1.1"
201 OK LIST SENT
@end example

@item DRIVER CAPABILITIES @var{driver-id}

Return information about the capabilities of the given driver.

The reply takes the following form. Each of the lines must be present
in the following order and carry one of the specified values.  @{a|b@}
means either a or b (but not both) is possible, while [a,b,c] means a,
b, c or any subset where items are separated by spaces.

@example
202-can_list_voices @{@code{true}|@code{false}@}
202-can_set_voice_by_properties @{@code{true}|@code{false}@}
202-can_get_current_voice @{@code{true}|@code{false}@}    
202-rate_settings [@code{absolute}, @code{relative}]
202-can_get_default_rate @{@code{true}|@code{false}@}
202-pitch_settings [@code{absolute}, @code{relative}]
202-can_get_default_pitch @{@code{true}|@code{false}@}
202-pitch_range_settings [@code{absolute}, @code{relative}]
202-can_get_pitch_range_default @{@code{true}|@code{false}@}
202-volume_settings [@code{absolute}, @code{relative}]
202-can_get_volume_default @{@code{true}|@code{false}@}
202-punctuation_modes [@code{all}, @code{none}, @code{some}]
202-can_set_punctuation_detail @{@code{true}|@code{false}@}
202-capital_letters_modes [@code{spelling}, @code{icon}, @code{pitch}]
202-can_set_number_grouping @{@code{true}|@code{false}@}
202-can_say_text_from_position @{@code{true}|@code{false}@}
202-can_say_char @{@code{true}|@code{false}@}
202-can_say_key @{@code{true}|@code{false}@}
202-can_say_icon @{@code{true}|@code{false}@}
202-can_set_dictionary @{@code{true}|@code{false}@}
202-audio_methods [@code{playback}, @code{retrieval}]
202-events [@code{by_sentences}, @code{by_words}, @code{by_index_marks}]
202-performance_level @{@code{none}|@code{good}|@code{excelent}@}
202-can_defer_message @{@code{true}|@code{false}@}
202-can_parse_ssml @{@code{true}|@code{false}@}
202-supports_multilingual_utterances @{@code{true}|@code{false}@}
202 OK DRIVER CAPABILITIES SENT
@end example

Example of usage (incomplete reply indicated by '[...]')

@example
DRIVER CAPABILITIES festival
202-can_list_voices @code{true}
202-can_set_voice_by_properties @code{true}
202-can_get_current_voice @code{true}    
202-rate_settings @code{relative} @code{absolute}
[...]
202-honors_performance_guidelines @code{excelent}
202-can_defer_message @code{false}
202-can_parse_ssml @code{true}
202-supports_multilingual_utterances @code{false}
202 OK DRIVER CAPABILITIES SENT
@end example

@end table

@node Voice Discovery, Speech Synthesis Commands (text protocol), Driver Discovery (text protocol), Text Protocol TTS API
@subsection Voice Discovery

@table @code

@anchor{LIST VOICES}
@item LIST VOICES @var{driver-id}

List voices available for a given driver.

The reply contains zero or more lines of the following form.
@example
203-"@var{name}" @var{language} "@var{dialect}" @{@code{MALE}|@code{FEMALE}@} @var{age}
@end example

Example usage:
@example
LIST VOICES festival
201-"kal" en nil MALE 30
201-"ked" en nil MALE 30
201-"czech_ph" cs nil MALE 30
201-"el_diphone" es nil MALE 48
201-"lp_diphone" it nil MALE 30
201-"pc_diphone" it nil FEMALE 30
201-OK LIST SENT
@end example
@end table

@node Speech Synthesis Commands (text protocol), Speech Control Commands (text protocol), Voice Discovery, Text Protocol TTS API
@subsection Speech Synthesis Commands (text protocol)

Commands listed in this section are actual request for synthesis (and
possibly playback) of a textual or sound message.

@table @code
@anchor{SAY TEXT}
@item SAY TEXT @var{format}

Start receiving a text message and synthesize it.  After sending a
reply to the command, the server waits for the text of the message.
The text can spread over any number of lines and is finished by an end
of line marker followed by the line containing the single character
@code{.} (dot).  Thus the complete character sequence closing the
input text is @code{CR LF . CR LF}.  If any line within the sent text
starts with a dot, an extra dot is prepended before it.

During reception of the text message, server doesn't send responses
for the lines sent.  The response line is sent only immediately after
the @code{SPEAK} command and after receiving the closing dot
line. Server can start input processing or speech synthesis as soon as
a sufficient amount of the text arrives; it generally needn't (but
may) wait until the end of data marker is received.

There is no explicit upper limit on the size of the text, but the
server administrator may set one in the configuration or the limit can
be enforced by available system resources.  If the limit is exceeded,
the whole text is accepted, but the excess is ignored and an error
response code is returned after processing the final dot line.

The content of the message can be either a plain text or a SSML
(Speech Synthesis Markup Language) text according to the @var{format}
argument. @var{format} can be either @code{SSML} or @code{PLAIN}.

Position where to start synthesis is specified as a non-negative
number @var{position} and the type of the event @var{position_type} as
specified in TTS API with one of the following values:
@code{MESSAGE_BEGIN}, @code{MESSAGE_END}, @code{SENTENCE_BEGIN},
@code{SENTENCE_END}, @code{WORD_BEGIN}, @code{WORD_END}.

The reply for the @code{SAY} command has the form

@example
204 OK RECEIVING DATA
@end example

and the reply to the end of text marker @code{CR LF . CR LF}
completing the whole composed command is

@example
203-@var{message-id}
204 OK MESSAGE RECEIVED
@end example

where @var{message-id} is a positive number representing the unique
message identification.

Example usage:
@example
SAY TEXT @emph{PLAIN}
203 OK RECEIVING DATA
Hello world!
.
204-67
204 OK MESSAGE RECEIVED
@end example

@anchor{SAY TEXT FROM POSITION}
@item SAY TEXT FROM POSITION @var{position} @var{position_type}

Same as (@pxref{SAY TEXT}) except synthesis is started from a given
event of type @var{position_type} on @var{position}
specified as a positive number.

@var{position_type} is one of @code{SENTENCE_BEGIN}, @code{SENTENCE_END},
@code{WORD_BEGIN}, @code{WORD_END}.

Example usage:
@example
SPEAK @emph{PLAIN} FROM POSITION @emph{2} @emph{WORD_BEGIN} 
203 OK RECEIVING DATA
Hello, world.
204-68
204 OK MESSAGE RECEIVED
@end example

@anchor{SAY TEXT FROM CHARACTER}
@item SAY TEXT @var{format} FROM CHARACTER @var{character_position}

Same as (@pxref{SAY TEXT}) except synthesis is started from a given
character position @var{character_position} specified as a non-negative
number.

Example usage:
@example
SPEAK @emph{PLAIN} FROM CHARACTER @emph{7}
203 OK RECEIVING DATA
Hello, world.
204-69
204 OK MESSAGE RECEIVED
@end example

@anchor{SAY TEXT FROM INDEX MARK}
@item SAY TEXT @var{format} FROM INDEX MARK "@var{index_mark}"

Same as (@pxref{SAY TEXT}) except synthesis is started from a
client supplied index mark @var{index_mark}.

Example usage:
@example
SPEAK @emph{SSML} FROM INDEX_MARK "test"
203 OK RECEIVING DATA
<speak>
Hello, <mark name="test">world.
</speak>
204-70
204 OK MESSAGE RECEIVED
@end example

@anchor{SAY DEFERRED}
@item SAY DEFERRED @var{message-id}

Similar to @pxref{SAY TEXT} except this commands
accepts no text.

@item SAY DEFERRED @var{message-id} FROM POSITION @var{position} @var{position_type}

Similar to @pxref{SAY TEXT FROM POSITION} except this commands
accepts no text.

@item SAY DEFERRED @var{message-id} FROM CHARACTER @var{character_position}

Similar to @pxref{SAY TEXT FROM CHARACTER} except this commands
accepts no text.

@item SAY DEFERRED @var{message-id} FROM INDEX MARK "@var{index_mark}"

Similar to @pxref{SAY TEXT FROM INDEX MARK} except this commands
accepts no text.

@anchor{SAY CHAR}
@item SAY CHAR @var{char}

Speak letter @var{char}.  @var{char} can be any character
representable by the UTF-8 encoding. The only exception is the
character space (@code{ }); that can't be sent directly. In this case,
a string @code{space} must be sent instead.

Example usage:
@example
SAY CHAR e
204-71
204 OK MESSAGE RECEIVED

SAY CHAR \
204-72
204 OK MESSAGE RECEIVED

SAY CHAR space
204-73
204 OK MESSAGE RECEIVED

SAY CHAR &
204-74
204 OK MESSAGE RECEIVED
@end example

This command is intended to be used for speaking single letters,
e.g. when reading a character under cursor or when spelling words.

@anchor{SAY KEY}
@item SAY KEY @var{key_name}

Example usage:
@example
SAY KEY shift_A
204-75
204 OK MESSAGE RECEIVED
@end example

Accept a key identified by @var{key_name} as message.  The command is
intended to be used for speaking keys pressed by the user.

@anchor{SAY ICON}
@item SAY ICON @var{icon_name}

Accept a general sound icon identified by @var{icon_name}.

Example usage:
@example
SAY ICON new-line
204-76
204 OK MESSAGE RECEIVED
@end example

@end table

@node Speech Control Commands (text protocol), Parameter Settings (text protocol), Speech Synthesis Commands (text protocol), Text Protocol TTS API
@subsection Speech Control Commands (text protocol)

@table @code
@item CANCEL

Immediately stop synthesis and audio output of the current message,
throw away all the data about this message and prepare the synthesizer
to receive a new message.

Example usage:
@example
CANCEL
209 OK CANCELED
@end example

@item DEFER

If synthesis and/or audio output are in progress, immediately stop
them. Keep the original text and as much data (possibly also audio) as
is needed to resume the message later via @code{SAY DEFERRED}.

Reply has the following form
@example
209-@var{message_id}
209 OK DEFERRED
@end example

where @var{message_id} is a unique positive number as defined in
TTS API.


Example usage:
@example
DEFER
209-47
209 OK DEFERRED
@end example

@item DISCARD @var{message_id}

Discards a previously deffered message.

Example usage:
@example
DISCARD 47
210 OK MESSAGE DISCARDED
@end example

@end table

@node Parameter Settings (text protocol), Event Callbacks (text protocol), Speech Control Commands (text protocol), Text Protocol TTS API
@subsection Parameter Settings (text protocol)

All settings except for driver selection only have effect
until the driver is changed.

Success return codes for all SET commands are
@example
211 OK PARAMETER SET
@end example

@menu
* Driver Selection and Parameters (text protocol)::  
* Voice Selection (text protocol)::  
* Prosody Parameters (text protocol)::  
* Style Parameters (text protocol)::  
* Dictionaries::                
* Audio Settings::              
@end menu

@node Driver Selection and Parameters (text protocol), Voice Selection (text protocol), Parameter Settings (text protocol), Parameter Settings (text protocol)
@subsubsection Driver Selection and Parameters (text protocol)

@table @code
@item SET DRIVER @var{driver_id}
Set the synthesis driver.

Example usage:
@example
SET DRIVER festival
211 OK PARAMETER SET
@end example
@end table

@node Voice Selection (text protocol), Prosody Parameters (text protocol), Driver Selection and Parameters (text protocol), Parameter Settings (text protocol)
@subsubsection Voice Selection (text protocol)

@table @code

@item SET VOICE BY NAME "@var{voice_name}"
Set voice by name for the synthesis driver in use.

Example usage:
@example
SET VOICE BY NAME "kal"
211 OK PARAMETER SET
@end example

@item SET VOICE BY PROPERTIES @var{language} "@var{dialect}" @var{gender} @var{age} @var{variant}
Set voice by the given properties.

Example usage:
@example
SET VOICE BY PROPERTIES cs nil FEMALE nil 0
211 OK PARAMETER SET
@end example

@item GET CURRENT VOICE

Return information about the currently used voice. The output
contains exactly two lines of this form:

@example
212-"@var{name}" @var{language} "@var{dialect}" @{@code{MALE}|@code{FEMALE}@} @var{age}
212 OK VOICE DESCRIPTION SENT
@end example

Example usage:
@example
GET CURRENT VOICE
212-"kal" en nil MALE 30
203-OK LIST OF VOICES SENT
@end example

@end table

@node Prosody Parameters (text protocol), Style Parameters (text protocol), Voice Selection (text protocol), Parameter Settings (text protocol)
@subsubsection Prosody Parameters (text protocol)

@table @code

@anchor{SET RATE}
@item SET @{@emph{RELATIVE}|@emph{ABSOLUTE}@} RATE @var{rate}

Set relative or absolute rate. @var{rate} is a positive or negative
number representing percents for relative changes, it is a positive
number representing words per minute for absolute changes.

Example usage
@example
SET RELATIVE RATE +300
211 OK PARAMETER SET

SET RELATIVE RATE -20
211 OK PARAMETER SET

SET RELATIVE RATE 150
211 OK PARAMETER SET
@end example

@item GET DEFAULT ABSOLUTE RATE

Get absolute value of default rate for the voice in use.

Reply is in the form:
@example
213-@var{absolute_rate}
213-OK ABSOLUTE RATE IN WPM SENT
@end example

where @var{absolute_rate} is a positive number representing
the rate in words per minute.

@item SET @{@emph{RELATIVE}|@emph{ABSOLUTE}@} PITCH @var{pitch}

Set relative or absolute rate. @var{pitch} is a positive or negative
number representing percents for relative changes, it is a positive
number representing Hertzs for absolute changes.

Examples are analogous to those for @pxref{SET RATE}

@item GET DEFAULT ABSOLUTE PITCH

Get default value of absolute pitch for the voice in use.

Reply is in the form:
@example
214-@var{pitch}
214-OK ABSOLUTE PITCH IN HZ SENT
@end example

where @var{pitch} is a positive number representing
the pitch in Hertzs.

@item SET @{@emph{RELATIVE}|@emph{ABSOLUTE}@} PITCH_RANGE @var{pitch_range}

Set relative or absolute pitch range. @var{pitch_range} is a positive or
negative number representing percents for relative changes, it is a
positive number representing Hertzs absolute changes.

Examples are analogous to those for @pxref{SET RATE}.

@item SET @{@emph{RELATIVE}|@emph{ABSOLUTE}@} VOLUME @var{volume}

Set relative or absolute volume. @var{volume} is a positive or negative
number representing percents for relative changes, it is a positive
number between 0 (silence) and 100 (max volume) for absolute changes.

Examples are analogous to those for @pxref{SET RATE}.

@item GET DEFAULT ABSOLUTE VOLUME

Get absolute value of default volume for the voice in use.

Reply is in the form:
@example
215-@var{pitch}
215-OK ABSOLUTE VOLUME IN DB SENT
@end example

where @var{volume} is a positive number.

@end table

@node Style Parameters (text protocol), Dictionaries, Prosody Parameters (text protocol), Parameter Settings (text protocol)
@subsubsection Style Parameters (text protocol)

@table @code
@item SET PUNCTUATION MODE @var{punctuation-mode}

Set punctuation mode to @var{punctuation-mode}. Allowed
values are @code{NONE}, @code{ALL}, @code{SOME}.

Example usage:
@example
SET PUNCTUATION MODE ALL
211 OK PARAMETER SET
@end example

@item SET PUNCTUATION DETAIL @var{detail}

Set the detail for punctuation reading when punctuation mode
is set to @code{SOME}. Detail is a string enumerating all
punctuation characters that should be explicitly pronounced.
The string must not contain any whitespace characters.

Example usage:
@example
SET PUNCTUATION DETAIL ?!.#
211 OK PARAMETER SET
@end example

@item SET CAPITAL LETTERS MODE @var{cap-let-mode}

Set capital letters reading mode. Allowed values
for the @var{cap-let-mode} parameter are: @code{NO},
@code{SPELLING}, @code{ICON}, @code{PITCH}.

Example usage:
@example
SET CAPITAL LETTERS MODE ICON
211 OK PARAMETER SET
@end example

@item SET NUMBER GROUPING @var{grouping}

Set grouping of digits for reading numbers. The parameter
@var{grouping} is a non-negative number.

@end table

@node Dictionaries, Audio Settings, Style Parameters (text protocol), Parameter Settings (text protocol)
@subsubsection Dictionaries

@node Audio Settings,  , Dictionaries, Parameter Settings (text protocol)
@subsubsection Audio Settings

@table @code

@item SET AUDIO OUTPUT @var{method}

Sets audio output method. Available values of the @var{method}
argument are @code{PLAYBACK} and @code{RETRIEVAL}.

Example usage:
@example
SET AUDIO OUTPUT PLAYBACK
211 OK PARAMETER SET
@end example

@item SET AUDIO RETRIEVAL DESTINATION @var{host} @var{port}

Sets destination for audio retrieval. @var{host} is the IP address of
the machine where audio data should be delivered.  The IP address is
written as groups of three digits separated by dots. @var{port}
is a positive number of the desired port.

Example usage:
@example
SET AUDIO RETRIEVAL DESTINATION 127.0.0.1 1315
211 OK PARAMETER SET
@end example

@end table

@node Event Callbacks (text protocol), Other Commands (text protocol), Parameter Settings (text protocol), Text Protocol TTS API
@subsection Event Callbacks (text protocol)

Event are reported on the main connection asynchronously and only if
the audio output method is set to @code{PLAYBACK}.  (If output method
is set to @code{RETRIEVAL}, information about events reached is sent
together with the audio data on the appropriate side channel).

Asynchronous nature of the event reports means such messages in the
protocol are not a result of a command being sent by the client and
may come at any time after a request for speaking (@code{SAY}) is
sent.  Such notifications can be sent even the @code{CANCEL} or
@code{DEFER} command is issued.

Information about each event is sent in this form:

@itemize
@item Message Events

@example
701-@var{type} @var{n} @var{pos_text}
701 MESSAGE EVENT
@end example

@item Sentence and Word Events

@example
702-@var{type} @var{n} @var{pos_text}
702 SENTENCE OR WORD EVENT
@end example

@item Index Mark Events

@example
703-@var{event-type} "@var{name}" @var{pos-text}
703 EVENT SENT
@end example
@end itemize

the exact meaning and format of the parameters is explained in TTS API
specifications under section Audio Retrieval. 

@node Other Commands (text protocol),  , Event Callbacks (text protocol), Text Protocol TTS API
@subsection Other Commands (text protocol)

@table @code
@item QUIT
Close the connection. No reply is sent and the connection is closed on
server side.

Example usage:
@example
QUIT
@end example

@item HELP
Print a short list of all available commands as a multi-line message.

The following format is used for reply:
@example
800-line 1
800-line 2
800 HELP SENT
@end example

Example usage:
@example
HELP
800-SAY
800-[...]
800-CANCEL
800-[...]
800-HELP
800 HELP SENT
@end example
@end table


@page
@node Python TTS API,  , Text Protocol TTS API, TTS API Implementations
@section Python TTS API

Python API is documented through docstrings and embedded comments.
Please see @file{src/ttsapi/client.py} in the source tree.

@bye
